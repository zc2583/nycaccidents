# Data transformation

## General Method
From the government website, we downloaded three csv files. When we inspect the data ,we found that except for some missing values, the data provide clean and straightforward information. The numerical inputs are in reasonable domain, and textual inputs are understandable.  
However, every dataset has over one million of rows, which is difficult for us to take the whole data in exploratory data analysis. Thus, we decided to randomly sample 10000 rows per dataset to save time.  

```{r eval=FALSE}
case_data_full<-read.csv("Case.csv")

set.seed(12)
case_data_sample<-case_data_full[sample(dim(case_data_full)[1], 10000),]

head(case_data_sample)
```

```{r eval=FALSE}
vehicle_data_full <- read_csv("Vehicle.csv")
set.seed(1)
index = sample(nrow(vehicle_data_full),10000, replace = FALSE)
vehicle_data_full <- vehicle_data_full[index,]
```

```{r  eval=FALSE}
individual_data_full <- read_csv("Individual.csv")
set.seed(2)
index = sample(nrow(individual_data_full),10000, replace = FALSE)
individual_data_full <- individual_data_full[index,]
```

## Unify Missing Values
Except for "NA", some inputs are labeled as "Unknown","Not Applicable","UNKNOWN VEHICLE","Not Entered","None" and so on. Thus, we also changed all of these labels which provide no information as "NA".  
